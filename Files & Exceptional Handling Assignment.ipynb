{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "### Files & Exceptional Handling Assignment ###",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "1. Discuss the scenarios where multithreading is preferable to multiprocessing and scenarios where multiprocessing is a better choice.\n\n2. Describe what a process pool is and how it helps in managing multiple processes efficiently.\n\n3. Explain what multiprocessing is and why it is used in Python programs.\n\n4. Write a Python program using multithreading where one thread adds numbers to a list, and another thread removes numbers from the list. Implement a mechanism to avoid race conditions using threading.Lock.\n\n5. Describe the methods and tools available in Python for safely sharing data between threads and processes.\n\n6. Discuss why it’s crucial to handle exceptions in concurrent programs and the techniques available for doing so.\n\n7. Create a program that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently. Use concurrent.futures.ThreadPoolExecutor to manage the threads.\n\n8. Create a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in parallel. Measure the time taken to perform this computation using a pool of different sizes (e.g., 2, 4, 8 processes).",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Answer1. Discuss the scenarios where multithreading is preferable to multiprocessing and scenarios where multiprocessing is a better choice.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "When deciding between multithreading and multiprocessing, the choice often depends on the specific requirements of our application and the nature of the tasks involved. Here’s a breakdown of scenarios where each approach is preferable:\n\n### When to Use Multithreading\n\n1. **I/O-Bound Tasks**:\n   - If your application spends a lot of time waiting for I/O operations (e.g., reading/writing files, network requests), multithreading can be more efficient. Threads can run concurrently, allowing one to handle I/O while others continue processing.\n\n2. **Shared Memory**:\n   - Multithreading is ideal when tasks need to share data. Since threads share the same memory space, data exchange between them is simpler and faster than inter-process communication (IPC) used in multiprocessing.\n\n3. **Low Memory Overhead**:\n   - Threads are generally lighter weight than processes. They consume less memory, making multithreading suitable for applications where resource consumption is a concern.\n\n4. **Real-Time Applications**:\n   - In scenarios where responsiveness is critical (e.g., GUI applications), multithreading can help keep the UI responsive while performing background tasks.\n\n5. **Frequent Context Switching**:\n   - If your application benefits from fast context switching (e.g., in a high-frequency trading application), threads can provide better performance compared to processes.\n\n### When to Use Multiprocessing\n\n1. **CPU-Bound Tasks**:\n   - For tasks that require heavy computation (e.g., numerical simulations, data processing), multiprocessing can utilize multiple CPU cores effectively. Each process runs in its own memory space, allowing better CPU resource utilization without the GIL (Global Interpreter Lock) constraints found in some languages like Python.\n\n2. **Isolation**:\n   - If tasks need to be isolated from each other to prevent crashes or memory leaks, multiprocessing is a safer choice. A crash in one process doesn’t affect others.\n\n3. **Avoiding GIL**:\n   - In languages with a GIL (like Python), multiprocessing allows multiple processes to run in parallel, overcoming the limitations of multithreading in such environments.\n\n4. **Scalability**:\n   - Multiprocessing can be more scalable for tasks that can be distributed across multiple machines or cores. This is useful in cloud computing and large-scale data processing tasks.\n\n5. **Long-Running Tasks**:\n   - For long-running tasks that can operate independently, using processes can keep the system stable. If one process fails, it doesn’t directly impact the others.\n\n### Conclusion\n\nChoosing between multithreading and multiprocessing depends on our specific use case. For I/O-bound and lightweight tasks where shared data is important, multithreading is often preferable. Conversely, for CPU-bound tasks that require isolation and scalability, multiprocessing is the better choice. Understanding the nature of our tasks and system architecture will help you make the right decision.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Answer2. Describe what a process pool is and how it helps in managing multiple processes efficiently.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "A **process pool** is a collection of pre-instantiated processes that can be used to perform tasks concurrently. This concept is particularly useful in managing multiple processes efficiently, especially in CPU-bound operations. Here’s how it works and its benefits:\n\n### How a Process Pool Works\n\n1. **Initialization**:\n   - A pool is created with a fixed number of worker processes. These processes are started and managed by a pool manager.\n\n2. **Task Submission**:\n   - When a task needs to be executed, instead of creating a new process for each task (which can be resource-intensive), the task is submitted to the pool. \n\n3. **Task Distribution**:\n   - The pool assigns available processes to execute the tasks. If all processes are busy, the task will wait in a queue until a process becomes available.\n\n4. **Result Retrieval**:\n   - Once a process completes a task, it returns the result to the pool manager, which can then be retrieved by the original requester.\n\n5. **Reusability**:\n   - The processes in the pool can be reused for multiple tasks, reducing the overhead of process creation and termination.\n\n### Benefits of Using a Process Pool\n\n1. **Efficiency**:\n   - By reusing processes, a process pool minimizes the overhead associated with starting and stopping processes, leading to better performance, especially in high-load scenarios.\n\n2. **Resource Management**:\n   - A process pool allows for better control over resource usage. You can limit the number of concurrent processes based on available system resources, preventing overloading the CPU and memory.\n\n3. **Scalability**:\n   - Process pools can be easily scaled. You can adjust the number of worker processes based on the workload, allowing the system to adapt to varying demands.\n\n4. **Simplified Error Handling**:\n   - Since tasks are handled by a defined set of processes, managing errors and exceptions becomes easier. If a process fails, the pool can reassign tasks to other available processes.\n\n5. **Improved Performance for CPU-Bound Tasks**:\n   - By effectively utilizing multiple CPU cores, process pools enhance the performance of CPU-bound applications, ensuring tasks are completed more quickly.\n\n6. **Asynchronous Task Handling**:\n   - Many process pool implementations support asynchronous task submissions and retrieval, allowing applications to continue executing while waiting for task results.\n\n### Example Use Cases\n\n- **Data Processing**: Large datasets can be processed in parallel, where each worker processes a chunk of data.\n- **Web Scraping**: Multiple pages can be scraped concurrently, improving overall throughput.\n- **Image Processing**: Tasks like resizing or filtering images can be distributed across multiple processes.\n\n### Conclusion\n\nIn summary, a process pool is a powerful design pattern for managing multiple processes efficiently. It provides a structured way to handle concurrent execution, reduces overhead, optimizes resource usage, and enhances performance, especially for CPU-intensive applications.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Answer3. Explain what multiprocessing is and why it is used in Python programs.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "**Multiprocessing** is a programming technique that allows a program to run multiple processes concurrently. In Python, this is particularly valuable due to the nature of the Global Interpreter Lock (GIL), which can limit the performance of CPU-bound tasks when using threads. Here’s a deeper look at what multiprocessing is and why it is commonly used in Python programs:\n\n### What is Multiprocessing?\n\n1. **Processes**:\n   - A process is an independent program in execution, with its own memory space. Unlike threads, processes do not share memory, which makes them isolated from one another.\n\n2. **Concurrency**:\n   - Multiprocessing allows for concurrent execution of multiple processes. This is achieved by utilizing multiple CPU cores, enabling true parallelism, which is especially beneficial for CPU-bound tasks.\n\n3. **Communication**:\n   - While processes do not share memory, they can communicate through mechanisms like pipes, queues, or shared memory. This allows for data exchange between processes when necessary.\n\n### Why Use Multiprocessing in Python?\n\n1. **Bypassing the GIL**:\n   - Python’s GIL allows only one thread to execute at a time in a single process, which can be a bottleneck for CPU-bound operations. Multiprocessing creates separate processes, each with its own Python interpreter and memory space, allowing multiple CPU cores to be utilized effectively.\n\n2. **Improving Performance**:\n   - For CPU-intensive tasks (e.g., numerical calculations, data processing), multiprocessing can lead to significant performance improvements by leveraging the full capabilities of multi-core processors.\n\n3. **Isolation**:\n   - Since processes run in separate memory spaces, they are isolated from one another. This means that if one process crashes or encounters an error, it does not affect the execution of other processes. This adds a level of robustness to applications.\n\n4. **Scalability**:\n   - Multiprocessing makes it easier to scale applications. You can adjust the number of processes according to available resources or workload, allowing applications to handle larger tasks more efficiently.\n\n5. **Simplicity in Code Structure**:\n   - The Python `multiprocessing` module provides a simple and intuitive API for creating and managing processes, making it easier for developers to implement concurrent execution without needing to manage low-level threading details.\n\n6. **Compatibility with Different Workloads**:\n   - Multiprocessing is suitable for various workloads, including data processing, web scraping, and simulations, where tasks can be executed independently.\n\n### Example Use Case\n\nConsider a scenario where you need to process a large dataset. Using the multiprocessing module, you can split the dataset into smaller chunks and process each chunk in a separate process. This approach can drastically reduce the overall processing time compared to a single-threaded or multi-threaded implementation.\n\n### Conclusion\n\nIn summary, multiprocessing in Python is a powerful technique for achieving concurrent execution, particularly for CPU-bound tasks. It allows developers to bypass the limitations of the GIL, improve performance, and create robust applications that can efficiently utilize multi-core processors.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Answer4. Write a Python program using multithreading where one thread adds numbers to a list, and another thread removes numbers from the list. Implement a mechanism to avoid race conditions using threading.Lock.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Here’s a Python program that demonstrates multithreading where one thread adds numbers to a list while another thread removes numbers from that list. To prevent race conditions, we’ll use threading.Lock to synchronize access to the shared list.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "import threading\nimport time\nimport random\n\n# Shared list and lock\nshared_list = []\nlock = threading.Lock()\n\ndef add_numbers():\n    \"\"\"Thread function to add numbers to the shared list.\"\"\"\n    for i in range(10):\n        num = random.randint(1, 100)\n        with lock:  # Acquire the lock before modifying the shared list\n            shared_list.append(num)\n            print(f\"Added: {num}, Current List: {shared_list}\")\n        time.sleep(random.uniform(0.1, 0.5))  # Simulate work\n\ndef remove_numbers():\n    \"\"\"Thread function to remove numbers from the shared list.\"\"\"\n    for _ in range(10):\n        with lock:  # Acquire the lock before modifying the shared list\n            if shared_list:\n                removed_num = shared_list.pop(0)\n                print(f\"Removed: {removed_num}, Current List: {shared_list}\")\n            else:\n                print(\"List is empty, nothing to remove.\")\n        time.sleep(random.uniform(0.1, 0.5))  # Simulate work\n\n# Create threads\nadd_thread = threading.Thread(target=add_numbers)\nremove_thread = threading.Thread(target=remove_numbers)\n\n# Start threads\nadd_thread.start()\nremove_thread.start()\n\n# Wait for both threads to complete\nadd_thread.join()\nremove_thread.join()\n\nprint(\"Final List:\", shared_list)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Explanation:\n1. Shared Resources:\n* A shared list (shared_list) is created to hold numbers.\n* A Lock object (lock) is used to synchronize access to the shared list.\n2. Adding Numbers:\n* The add_numbers function runs in one thread. It generates random numbers and adds them to the shared list while acquiring the lock to ensure exclusive access.\n3. Removing Numbers:\n* The remove_numbers function runs in another thread. It removes numbers from the shared list, also using the lock to prevent simultaneous access.\n4. Thread Creation:\n* Two threads are created: one for adding numbers and another for removing numbers.\n5. Starting and Joining Threads:\n* The threads are started using start(), and join() is used to ensure the main program waits for both threads to complete before printing the final state of the list.\n\n### Running the Program\nWhen you run this program, you should see messages indicating numbers being added and removed from the list while avoiding race conditions, thanks to the locking mechanism.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Answer5. Describe the methods and tools available in Python for safely sharing data between threads and processes.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "In Python, there are several methods and tools available for safely sharing data between threads and processes. These mechanisms help prevent race conditions and ensure data integrity. Here’s a breakdown of the most common approaches:\n\n1. Threading Module (for threads)\n* Locks: A Lock is a basic synchronization primitive that allows only one thread to access a resource at a time. This is used to prevent race conditions.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "from threading import Lock\n\nlock = Lock()\nwith lock:\n    # Critical section",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "* RLocks (Reentrant Locks): Similar to locks, but allow the same thread to acquire the lock multiple times without blocking itself.\n* Condition Variables: These are used for signaling between threads. One thread can signal another thread to wake up or continue execution.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "from threading import Condition\n\ncondition = Condition()\n\nwith condition:\n    # Wait for a signal\n    condition.wait()\n    # Send a signal\n    condition.notify()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "* Semaphores: A semaphore is a counter that controls access to a shared resource. It allows a limited number of threads to access a resource at the same time.\n* Queues: The queue.Queue class provides a thread-safe FIFO queue that can be used to share data between threads safely.\n\n2. Multiprocessing Module (for processes)\n* Queues: Similar to threading, multiprocessing.Queue provides a way for processes to communicate safely. It uses locks internally, so you don’t have to manage them yourself.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "from multiprocessing import Queue\n\nqueue = Queue()\nqueue.put(data)\ndata = queue.get()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "* Pipes: multiprocessing.Pipe creates a two-way communication channel between processes. It's useful for sending data directly between them.\n* Manager: The multiprocessing.Manager class allows you to create shared objects, such as lists and dictionaries, that can be safely modified by multiple processes.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "from multiprocessing import Manager\n\nmanager = Manager()\nshared_list = manager.list()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "3. Concurrent Futures\nThe concurrent.futures module provides a high-level interface for asynchronously executing callables.\n* ThreadPoolExecutor: For managing a pool of threads. It abstracts away the need to manually manage threads, locks, etc.\n* ProcessPoolExecutor: Similar to ThreadPoolExecutor, but for managing a pool of processes.\n\n4. Asynchronous Programming\nWhile not strictly about threads or processes, Python’s asyncio library provides a way to write concurrent code using the async/await syntax. This is more suitable for I/O-bound tasks.\n\n### Summary\nWhen choosing the right method for sharing data:\n* Use locks or conditions for thread synchronization.\n* Use queues for safe inter-thread or inter-process communication.\n* Use multiprocessing Manager for shared state among processes.\n* For high-level task management, consider concurrent.futures.\n\nEach of these tools has its own use cases, and the choice depends on the specific requirements of our application, such as whether it is I/O-bound or CPU-bound, and how complex the data sharing needs to be.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Answer6. Discuss why it’s crucial to handle exceptions in concurrent programs and the techniques available for doing so.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Handling exceptions in concurrent programs is crucial for several reasons:\n\n### Importance of Exception Handling in Concurrent Programs:\n1. Unpredictable State: In concurrent programming, multiple threads or processes can interact in complex ways. If an exception occurs in one part of the program and is not handled properly, it can lead to inconsistent states, resource leaks, or crashes that affect other threads or processes.\n2. Debugging Difficulty: Exceptions can propagate in unpredictable ways across threads or processes, making it difficult to trace the source of errors. Proper exception handling can provide clearer error messages and help isolate issues.\n3. Resource Management: Without proper exception handling, resources such as file handles, network connections, or memory can remain locked or unfreed, leading to resource exhaustion and degraded performance.\n4. User Experience: In applications with user interfaces, unhandled exceptions can lead to crashes or freezes, significantly affecting user experience. Proper handling can allow for graceful recovery or informative error messages.\n5. Maintaining Application Logic: Properly managing exceptions can allow the program to continue running, retry operations, or perform cleanup actions that maintain the intended application logic.\n\n### Techniques for Handling Exceptions in Concurrent Programs:\n1. Try-Except Blocks:\n* Use try-except blocks around code that may raise exceptions. This allows you to catch and handle exceptions locally within a thread or process.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "try:\n    # Code that may raise an exception\nexcept Exception as e:\n    # Handle exception",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "2. Logging:\n* Incorporate logging within the exception handling to record errors for debugging. This is especially useful in concurrent programs where tracing the flow of execution can be challenging.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "import logging\n\nlogging.basicConfig(level=logging.ERROR)\n\ntry:\n    # Code that may raise an exception\nexcept Exception as e:\n    logging.error(f\"An error occurred: {e}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "3. Using Futures (in concurrent.futures):\n* When using ThreadPoolExecutor or ProcessPoolExecutor, you can retrieve exceptions from futures. The result() method raises the exception if the callable raised one.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "from concurrent.futures import ThreadPoolExecutor\n\ndef task():\n    raise ValueError(\"An error occurred\")\n\nwith ThreadPoolExecutor() as executor:\n    future = executor.submit(task)\n    try:\n        result = future.result()\n    except Exception as e:\n        print(f\"Caught an exception: {e}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "4. Graceful Shutdown:\n* Implementing a mechanism to handle exceptions that allows for a clean shutdown of threads or processes can prevent resource leaks and ensure that all parts of the application are closed properly.\n\n5. Thread-specific Exception Handling:\n* If using threads, consider setting a thread-local storage for exceptions. This way, you can catch exceptions that occur in one thread without affecting others.\n\n6. Custom Exception Classes:\n* Create custom exception classes for specific errors in your concurrent code. This helps to differentiate between different types of errors and handle them appropriately.\n\n### Summary\nProper exception handling in concurrent programs is essential for maintaining application stability, resource integrity, and a good user experience. By employing techniques such as try-except blocks, logging, future result handling, and graceful shutdown mechanisms, developers can effectively manage errors and ensure that their concurrent applications are robust and resilient.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Answer7. Create a program that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently. Use concurrent.futures.ThreadPoolExecutor to manage the threads.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Here's a Python program that uses concurrent.futures.ThreadPoolExecutor to calculate the factorial of numbers from 1 to 10 concurrently:",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "import concurrent.futures\nimport math\n\ndef factorial(n):\n    \"\"\"Calculate the factorial of a number.\"\"\"\n    return math.factorial(n)\n\ndef main():\n    numbers = list(range(1, 11))  # Numbers from 1 to 10\n    \n    # Using ThreadPoolExecutor to manage threads\n    with concurrent.futures.ThreadPoolExecutor() as executor:\n        # Map the factorial function to the numbers\n        results = list(executor.map(factorial, numbers))\n\n    # Print the results\n    for number, result in zip(numbers, results):\n        print(f\"Factorial of {number} is {result}\")\n\nif __name__ == \"__main__\":\n    main()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Explanation:\n1. Factorial Function: The factorial function computes the factorial of a given number using math.factorial, which is efficient and handles large integers.\n2. Main Function:\n* A list of numbers from 1 to 10 is created.\n* A ThreadPoolExecutor is instantiated using a context manager, which automatically handles the thread pool's lifecycle.\n* The executor.map method is used to apply the factorial function to each number in the list concurrently.\n3. Output: After collecting the results, the program prints the factorial of each number.\n\n### Running the Program\nWhen you run the program, it will calculate and print the factorials of numbers from 1 to 10 concurrently, demonstrating the power of thread pooling in Python.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Answer8. Create a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in parallel. Measure the time taken to perform this computation using a pool of different sizes (e.g., 2, 4, 8 processes).",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Here's a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in parallel. The program also measures the time taken for different pool sizes (2, 4, and 8 processes):",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "import multiprocessing\nimport time\n\ndef square(n):\n    \"\"\"Compute the square of a number.\"\"\"\n    return n * n\n\ndef main():\n    numbers = list(range(1, 11))  # Numbers from 1 to 10\n    pool_sizes = [2, 4, 8]  # Different pool sizes\n\n    for pool_size in pool_sizes:\n        # Measure the time taken for each pool size\n        start_time = time.time()\n        \n        with multiprocessing.Pool(processes=pool_size) as pool:\n            results = pool.map(square, numbers)\n        \n        end_time = time.time()\n        \n        # Print the results and time taken\n        print(f\"Results with pool size {pool_size}: {results}\")\n        print(f\"Time taken: {end_time - start_time:.4f} seconds\\n\")\n\nif __name__ == \"__main__\":\n    main()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Explanation:\n1. Square Function: The square function takes a number n and returns its square.\n2. Main Function:\n* A list of numbers from 1 to 10 is created.\n* The program iterates over a list of different pool sizes (2, 4, and 8).\n* For each pool size, it measures the time taken to compute the squares using a multiprocessing.Pool.\n* The pool.map method is used to apply the square function to the list of numbers concurrently.\n* The results and the time taken for each pool size are printed.\n\n### Running the Program\nWhen you run the program, it will compute the squares of numbers from 1 to 10 using the specified pool sizes and display the results along with the time taken for each computation. This demonstrates how multiprocessing can be utilized to perform computations in parallel efficiently.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}